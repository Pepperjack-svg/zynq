worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /tmp/nginx.pid;

# ── WHY >5 GB UPLOADS SILENTLY FAILED ──────────────────────────────────────
# Two root causes:
#   1. client_max_body_size was 1G on the upload location — nginx returns 413
#      but the TCP FIN races with the client's data stream, making it look like
#      a silent connection drop instead of a clean error.
#   2. proxy_read_timeout 300s — a client uploading 5 GB at 2 MB/s takes
#      ~42 minutes. nginx closed the upstream connection after 5 minutes,
#      again appearing silent from the client's perspective.
#   3. With proxy_request_buffering ON (the default), nginx tries to spool the
#      entire body to /tmp/nginx_client_body before forwarding. A 5 GB upload
#      can exhaust the temp disk or the client_max_body_size limit mid-buffer.
#
# Fixes applied below:
#   - client_max_body_size 0 on upload locations (unlimited; Go enforces limits)
#   - proxy_request_buffering off (stream immediately, no nginx temp disk)
#   - proxy_read_timeout / proxy_send_timeout 3600s (1 hour)
#   - send_timeout 3600s (covers slow-writing clients on the response side)
# ────────────────────────────────────────────────────────────────────────────

events {
    # 1024 is fine for a single-node deployment.
    # For 100k concurrent uploads behind a load balancer, each nginx node
    # only sees a fraction — raise to 4096+ if nginx is the single entry point.
    worker_connections 4096;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" rt=$request_time';
    access_log /var/log/nginx/access.log main;

    sendfile           on;
    tcp_nopush         on;
    tcp_nodelay        on;

    # Default keepalive for short API calls.
    keepalive_timeout  65;

    # Global body size limit for non-upload routes (protects JSON endpoints).
    # Upload locations override this with 0 (unlimited).
    client_max_body_size 10M;

    # Temp paths for non-root operation.
    client_body_temp_path /tmp/nginx_client_body;
    proxy_temp_path       /tmp/nginx_proxy;
    fastcgi_temp_path     /tmp/nginx_fastcgi;
    uwsgi_temp_path       /tmp/nginx_uwsgi;
    scgi_temp_path        /tmp/nginx_scgi;

    upstream backend {
        server 127.0.0.1:4000;
        keepalive 64;
    }

    upstream frontend {
        server 127.0.0.1:3000;
        keepalive 32;
    }

    server {
        listen 80;
        server_name _;

        # ── File upload endpoints (single-file and chunked parts) ─────────────
        #
        # These locations handle multi-GB streaming bodies. Key settings:
        #
        #   client_max_body_size 0          — nginx enforces no size limit;
        #                                     the Go service uses MaxBytesReader
        #                                     on JSON-only endpoints and streams
        #                                     binary upload bodies directly.
        #
        #   proxy_request_buffering off     — nginx forwards bytes to Go as they
        #                                     arrive. Without this, nginx must
        #                                     buffer the entire body in
        #                                     client_body_temp_path before
        #                                     opening the upstream connection,
        #                                     which fails when the file exceeds
        #                                     the temp disk space or the nginx
        #                                     client_max_body_size.
        #
        #   proxy_read_timeout 3600s        — time nginx waits for the upstream
        #                                     to produce a response byte. For a
        #                                     10 GB file on a slow disk, assembly
        #                                     can take minutes after the last
        #                                     network byte arrives.
        #
        #   proxy_send_timeout 3600s        — time nginx waits between two
        #                                     successive writes to the upstream.
        #                                     Slow disk I/O or scheduler pauses
        #                                     can stall write bursts.
        #
        #   send_timeout 3600s              — time nginx waits between two
        #                                     writes to the client on the
        #                                     response path. Relevant for large
        #                                     downloads.
        #
        #   keepalive_timeout 3600s         — keep the upstream connection alive
        #                                     for the duration of the upload.

        # Single-file upload — exact match so the large-body / long-timeout
        # settings apply only to POST /api/v1/files and not to download or
        # delete requests on /api/v1/files/{owner}/{fileId}.
        location = /api/v1/files {
            client_max_body_size    0;
            proxy_request_buffering off;
            proxy_http_version      1.1;
            proxy_set_header        Connection "";
            proxy_set_header        Host              $host;
            proxy_set_header        X-Real-IP         $remote_addr;
            proxy_set_header        X-Forwarded-For   $proxy_add_x_forwarded_for;
            proxy_set_header        X-Forwarded-Proto $scheme;
            proxy_read_timeout      3600s;
            proxy_send_timeout      3600s;
            send_timeout            3600s;
            keepalive_timeout       3600s;
            proxy_pass              http://backend;
        }

        # Chunked / resumable upload parts
        location ~ ^/api/v1/uploads {
            client_max_body_size    0;
            proxy_request_buffering off;
            proxy_http_version      1.1;
            proxy_set_header        Connection "";
            proxy_set_header        Host              $host;
            proxy_set_header        X-Real-IP         $remote_addr;
            proxy_set_header        X-Forwarded-For   $proxy_add_x_forwarded_for;
            proxy_set_header        X-Forwarded-Proto $scheme;
            proxy_read_timeout      3600s;
            proxy_send_timeout      3600s;
            send_timeout            3600s;
            keepalive_timeout       3600s;
            proxy_pass              http://backend;
        }

        # ── All other API requests ────────────────────────────────────────────
        location /api/ {
            proxy_pass              http://backend;
            proxy_http_version      1.1;
            proxy_set_header        Connection "";
            proxy_set_header        Host              $host;
            proxy_set_header        X-Real-IP         $remote_addr;
            proxy_set_header        X-Forwarded-For   $proxy_add_x_forwarded_for;
            proxy_set_header        X-Forwarded-Proto $scheme;
            proxy_read_timeout      60s;
            proxy_send_timeout      60s;
        }

        # ── Frontend (Next.js) ────────────────────────────────────────────────
        location / {
            proxy_pass         http://frontend;
            proxy_http_version 1.1;
            proxy_set_header   Host              $host;
            proxy_set_header   X-Real-IP         $remote_addr;
            proxy_set_header   X-Forwarded-For   $proxy_add_x_forwarded_for;
            proxy_set_header   X-Forwarded-Proto $scheme;
            proxy_set_header   Upgrade           $http_upgrade;
            proxy_set_header   Connection        "upgrade";
        }

        # ── Health check ─────────────────────────────────────────────────────
        location /health {
            proxy_pass http://backend/api/v1/health;
        }
    }
}
